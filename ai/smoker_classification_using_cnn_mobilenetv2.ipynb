{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 420647,
          "sourceType": "datasetVersion",
          "datasetId": 188204
        }
      ],
      "dockerImageVersionId": 30235,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1 style=\"font-family:verdana;\"> <center>üö¨Smoker Classification using Deep Convolutional Neural Networks and Transfer Learning</center> </h1>\n",
        "<p><center style=\"color:#159364; font-family:cursive;\">Thanks for visiting my notebook </center></p>\n",
        "\n",
        "***\n",
        "\n",
        "<center><img src='https://media3.giphy.com/media/9W4KAgmmGvcIF6P8iY/200w.webp?cid=ecf05e473qplvdozs353bno889z16wtdvrc9e1q4rnzfg9x3&rid=200w.webp&ct=s' height=150px width=200px></center>\n",
        "\n",
        "# üëãThanks for Visting my Notebook\n",
        "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
        "    üìå Feel free to fork or edit the notebook for your own convenience. If you liked the notebook, consider upvoting. It helps other people discover the notebook as well. Your support inspires me to produce more of these kernel.üòä\n",
        "</div>\n",
        "\n",
        "# üî¨Overview\n",
        "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">Tobacco is extremely harmful and there is no safe level of exposure to it. While cigarette smoking is the most widespread form of tobacco use, other tobacco products like waterpipe tobacco, various smokeless tobacco products, cigars, cigarillos, roll-your-own tobacco, pipe tobacco, bidis and kreteks are also harmful. Research has proved that more than half of tobacco users are eventually killed by it. Currently, 7 million tobacco users die every year. The negative effects of using tobacco range from physical impacts like shortness of breath, throat and tongue cancer to mental impacts like increased anxiety and stress.</p>\n",
        "\n",
        "\n",
        "<h3><b>The health benefits of quitting tobacco</b></h3>\n",
        "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">Quitting tobacco is not easy, but the health benefits far outweigh the health risks. When you stop smoking, the benefits start almost immediately. Your heart rate and blood pressure drop in only 20 minutes. Within 12 hours, the carbon monoxide level in your blood returns to normal and coughing and shortness of breath can decrease in as little as one month. Ultimately, when you quit tobacco, you will experience improved breathing with healthy lungs and increase your chances of a longer life.  <a href='https://www.who.int/campaigns/Florence'>Source</a></p>\n",
        "\n",
        "\n",
        "# ‚ùóAuthor's Note:\n",
        "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">Make sure to run the cells from top to bottom with a GPU accelerator. There are some linux commands present in some cells so this is important to take into account. Also, any suggestions, comments and recommendations to improve the notebook will be highly appreciated. Cheers!</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "n6QHvU2dfpFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèóÔ∏èImport Necessary Libraries"
      ],
      "metadata": {
        "id": "kQELj5Dwf3on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Data Science Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "# Import visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import cv2\n",
        "\n",
        "# Tensorflow Libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,models\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# System libraries\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "lEzJXgjDf5y8",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:12.132587Z",
          "iopub.execute_input": "2023-12-25T15:33:12.133122Z",
          "iopub.status.idle": "2023-12-25T15:33:13.332185Z",
          "shell.execute_reply.started": "2023-12-25T15:33:12.133079Z",
          "shell.execute_reply": "2023-12-25T15:33:13.331068Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ôCreate helper functions"
      ],
      "metadata": {
        "id": "D_SnZPRah_9D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "wrlkwO6fnlrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### We create a bunch of helpful functions throughout the course.\n",
        "### Storing them here so they're easily accessible.\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224, scale=True):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
        "  (224, 224, 3).\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  filename (str): string filename of target image\n",
        "  img_shape (int): size to resize target image to, default 224\n",
        "  scale (bool): whether to scale pixel values to range(0, 1), default True\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img = tf.image.decode_jpeg(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "  if scale:\n",
        "    # Rescale the image (get all values between 0 and 1)\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img\n",
        "\n",
        "# Note: The following confusion matrix code is a remix of Scikit-Learn's\n",
        "# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Our function needs a different name to sklearn's plot_confusion_matrix\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):\n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "\n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"\n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "\n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes),\n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "\n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"confusion_matrix.png\")\n",
        "\n",
        "# Make a function to predict on images and plot them (works with multi-class)\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  if len(pred[0]) > 1: # check for multi-class\n",
        "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);\n",
        "\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Creates a TensorBoard callback instand to store log files.\n",
        "\n",
        "  Stores log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "\n",
        "  Args:\n",
        "    dir_name: target directory to store TensorBoard log files\n",
        "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "\n",
        "# Plot the validation and training data separately\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "\n",
        "  Args:\n",
        "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
        "  \"\"\"\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n",
        "\n",
        "def compare_historys(original_history, new_history, initial_epochs=5):\n",
        "    \"\"\"\n",
        "    Compares two TensorFlow model History objects.\n",
        "\n",
        "    Args:\n",
        "      original_history: History object from original model (before new_history)\n",
        "      new_history: History object from continued model training (after original_history)\n",
        "      initial_epochs: Number of epochs in original_history (new_history plot starts from here)\n",
        "    \"\"\"\n",
        "\n",
        "    # Get original history measurements\n",
        "    acc = original_history.history[\"accuracy\"]\n",
        "    loss = original_history.history[\"loss\"]\n",
        "\n",
        "    val_acc = original_history.history[\"val_accuracy\"]\n",
        "    val_loss = original_history.history[\"val_loss\"]\n",
        "\n",
        "    # Combine original history with new history\n",
        "    total_acc = acc + new_history.history[\"accuracy\"]\n",
        "    total_loss = loss + new_history.history[\"loss\"]\n",
        "\n",
        "    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
        "    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
        "\n",
        "    # Make plots\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(total_acc, label='Training Accuracy')\n",
        "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(total_loss, label='Training Loss')\n",
        "    plt.plot(total_val_loss, label='Validation Loss')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()\n",
        "\n",
        "# Create function to unzip a zipfile into current working directory\n",
        "# (since we're going to be downloading and unzipping a few files)\n",
        "import zipfile\n",
        "\n",
        "def unzip_data(filename):\n",
        "  \"\"\"\n",
        "  Unzips filename into the current working directory.\n",
        "\n",
        "  Args:\n",
        "    filename (str): a filepath to a target zip folder to be unzipped.\n",
        "  \"\"\"\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()\n",
        "\n",
        "# Walk through an image classification directory and find out how many files (images)\n",
        "# are in each subdirectory.\n",
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "\n",
        "  Args:\n",
        "    dir_path (str): target directory\n",
        "\n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "\n",
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "      y_true: true labels in the form of a 1D array\n",
        "      y_pred: predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:13.334728Z",
          "iopub.execute_input": "2023-12-25T15:33:13.335240Z",
          "iopub.status.idle": "2023-12-25T15:33:13.386177Z",
          "shell.execute_reply.started": "2023-12-25T15:33:13.335190Z",
          "shell.execute_reply": "2023-12-25T15:33:13.384996Z"
        },
        "trusted": true,
        "id": "k_uIBb56nlrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# # Import series of helper functions for our notebook\n",
        "# from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot"
      ],
      "metadata": {
        "id": "F8ReVC2MiBRZ",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:13.387418Z",
          "iopub.execute_input": "2023-12-25T15:33:13.389245Z",
          "iopub.status.idle": "2023-12-25T15:33:13.411866Z",
          "shell.execute_reply.started": "2023-12-25T15:33:13.389172Z",
          "shell.execute_reply": "2023-12-25T15:33:13.410377Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì•Load and Transform Data"
      ],
      "metadata": {
        "id": "Hb_XPhOwiCNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kyXyH3kfn5Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !chmod 600 /root/.kaggle/kaggle.json\n",
        "# !kaggle datasets download -d vitaminc/cigarette-smoker-detection\n",
        "# !unzip /content/cigarette-smoker-detection.zip -d /content\n",
        "# !rm /content/cigarette-smoker-detection.zip"
      ],
      "metadata": {
        "id": "kTbvsC_Nnw4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = (300, 300)"
      ],
      "metadata": {
        "id": "8nD56d7Xxmc3",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:13.415260Z",
          "iopub.execute_input": "2023-12-25T15:33:13.416211Z",
          "iopub.status.idle": "2023-12-25T15:33:13.425315Z",
          "shell.execute_reply.started": "2023-12-25T15:33:13.416155Z",
          "shell.execute_reply": "2023-12-25T15:33:13.423921Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Walk through each directory\n",
        "dataset = \"/content/data/\"\n",
        "walk_through_dir(dataset)"
      ],
      "metadata": {
        "id": "5kXkjadNxsNI",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:13.426912Z",
          "iopub.execute_input": "2023-12-25T15:33:13.427551Z",
          "iopub.status.idle": "2023-12-25T15:33:18.890680Z",
          "shell.execute_reply.started": "2023-12-25T15:33:13.427495Z",
          "shell.execute_reply": "2023-12-25T15:33:18.889040Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìÖPlacing data into a Dataframe\n",
        "The first column `filepaths` contains the file path location of each individual images. The second column `labels`, on the other hand, contains the class label of the corresponding image from the file path"
      ],
      "metadata": {
        "id": "MLAnhGlf1hmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = Path(dataset)\n",
        "\n",
        "# Get filepaths and labels\n",
        "filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png'))  + list(image_dir.glob(r'**/*.jpeg')) + list(image_dir.glob(r'**/*.gif'))\n",
        "\n",
        "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
        "\n",
        "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "labels = pd.Series(labels, name='Label')\n",
        "\n",
        "# Concatenate filepaths and labels\n",
        "image_df = pd.concat([filepaths, labels], axis=1)"
      ],
      "metadata": {
        "id": "s14XOEp01m_s",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:18.892740Z",
          "iopub.execute_input": "2023-12-25T15:33:18.893793Z",
          "iopub.status.idle": "2023-12-25T15:33:19.827425Z",
          "shell.execute_reply.started": "2023-12-25T15:33:18.893748Z",
          "shell.execute_reply": "2023-12-25T15:33:19.826128Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_df"
      ],
      "metadata": {
        "id": "d3-uoP4n1oqK",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:19.829192Z",
          "iopub.execute_input": "2023-12-25T15:33:19.829572Z",
          "iopub.status.idle": "2023-12-25T15:33:19.858020Z",
          "shell.execute_reply.started": "2023-12-25T15:33:19.829535Z",
          "shell.execute_reply": "2023-12-25T15:33:19.856985Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìùData Preprocessing\n",
        "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">The data will be split into three different categories: Training, Validation and Testing. The training data will be used to train the deep learning CNN model and its parameters will be fine tuned with the validation data. Finally, the performance of the data will be evaluated using the test data(data the model has not previously seen).</p>"
      ],
      "metadata": {
        "id": "YwC4EWei1s-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate in train and test data\n",
        "train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "xaJlHTlz2K4M",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:32.067086Z",
          "iopub.execute_input": "2023-12-25T15:33:32.067444Z",
          "iopub.status.idle": "2023-12-25T15:33:32.078545Z",
          "shell.execute_reply.started": "2023-12-25T15:33:32.067410Z",
          "shell.execute_reply": "2023-12-25T15:33:32.077135Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
        ")"
      ],
      "metadata": {
        "id": "3puUVDwl2Mcz",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:32.080405Z",
          "iopub.execute_input": "2023-12-25T15:33:32.081430Z",
          "iopub.status.idle": "2023-12-25T15:33:32.088127Z",
          "shell.execute_reply.started": "2023-12-25T15:33:32.081387Z",
          "shell.execute_reply": "2023-12-25T15:33:32.086699Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into three categories.\n",
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "CsftNShQ2PaK",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:32.090145Z",
          "iopub.execute_input": "2023-12-25T15:33:32.090578Z",
          "iopub.status.idle": "2023-12-25T15:33:35.544538Z",
          "shell.execute_reply.started": "2023-12-25T15:33:32.090538Z",
          "shell.execute_reply": "2023-12-25T15:33:35.543412Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize Layer\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Resizing(224,224),\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "  layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  layers.experimental.preprocessing.RandomContrast(0.1),\n",
        "])"
      ],
      "metadata": {
        "id": "sLbR4WtD2RPg",
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:35.546197Z",
          "iopub.execute_input": "2023-12-25T15:33:35.547088Z",
          "iopub.status.idle": "2023-12-25T15:33:35.632141Z",
          "shell.execute_reply.started": "2023-12-25T15:33:35.547041Z",
          "shell.execute_reply": "2023-12-25T15:33:35.631138Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§πTraining the model\n",
        "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">The model images will be subjected to a pre-trained CNN model called MobileNetV2. Three callbacks will be utilized to monitor the training. These are: Model Checkpoint, Early Stopping, Tensorboard callback. The summary of the model hyperparameter is shown as follows:</p>\n",
        "\n",
        "**Batch size** : 32\n",
        "\n",
        "**Epochs** : 100\n",
        "\n",
        "**Input Shape** : (224, 224, 3)\n",
        "\n",
        "**Output layer** : 2\n",
        "\n"
      ],
      "metadata": {
        "id": "xSEhK2w02Uk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretained model\n",
        "pretrained_model = tf.keras.applications.InceptionResNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='max'\n",
        ")\n",
        "\n",
        "pretrained_model.trainable = False"
      ],
      "metadata": {
        "id": "z4VI_UxV2Wp2",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:34:40.027119Z",
          "iopub.execute_input": "2023-12-25T15:34:40.027625Z",
          "iopub.status.idle": "2023-12-25T15:35:05.346564Z",
          "shell.execute_reply.started": "2023-12-25T15:34:40.027583Z",
          "shell.execute_reply": "2023-12-25T15:35:05.344711Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create checkpoint callback\n",
        "checkpoint_path = \"smokers_classification_model_checkpoint\"\n",
        "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
        "                                      save_weights_only=True,\n",
        "                                      monitor=\"val_accuracy\",\n",
        "                                      save_best_only=True)"
      ],
      "metadata": {
        "id": "1xn6j_La2Y2u",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:57.128473Z",
          "iopub.status.idle": "2023-12-25T15:33:57.129393Z",
          "shell.execute_reply.started": "2023-12-25T15:33:57.129074Z",
          "shell.execute_reply": "2023-12-25T15:33:57.129105Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWxeUam01kFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 5 epochs\n",
        "early_stopping = EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
        "                               patience = 5,\n",
        "                               restore_best_weights = True) # if val loss decreases for 5 epochs in a row, stop training"
      ],
      "metadata": {
        "id": "YbP7g6Xh2abB",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:57.131206Z",
          "iopub.status.idle": "2023-12-25T15:33:57.132139Z",
          "shell.execute_reply.started": "2023-12-25T15:33:57.131784Z",
          "shell.execute_reply": "2023-12-25T15:33:57.131816Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÑTraining the model"
      ],
      "metadata": {
        "id": "alynENS02jm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = pretrained_model.input\n",
        "x = resize_and_rescale(inputs)\n",
        "\n",
        "x = Dense(256, activation='relu')(pretrained_model.output)\n",
        "x = Dropout(0.45)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.45)(x)\n",
        "\n",
        "\n",
        "outputs = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(0.00001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    steps_per_epoch=len(train_images),\n",
        "    validation_data=val_images,\n",
        "    validation_steps=len(val_images),\n",
        "    epochs=5,\n",
        "    callbacks=[\n",
        "        early_stopping,\n",
        "        create_tensorboard_callback(\"training_logs\",\n",
        "                                    \"smoker_classification\"),\n",
        "        checkpoint_callback,\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "AkcAsl5H2tYl",
        "outputId": "430a3802-dd54-4ed8-98c4-bbb7f2c74081",
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:57.133846Z",
          "iopub.status.idle": "2023-12-25T15:33:57.134719Z",
          "shell.execute_reply.started": "2023-12-25T15:33:57.134398Z",
          "shell.execute_reply": "2023-12-25T15:33:57.134429Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: training_logs/smoker_classification/20231226-022431\n",
            "Epoch 1/5\n",
            "  6/130 [>.............................] - ETA: 18:49 - loss: 2.5240 - accuracy: 0.5417"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/\")"
      ],
      "metadata": {
        "id": "7v6Za1j53RoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úîÔ∏èModel Evaluation\n",
        "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">The test dataset will be used to evaluate the performance of the model.One of the metrics that will be tested would be accuracy which measures the fraction of predictions the model got right. Other metrics are as follows:   </p>\n",
        "\n",
        "<h3>Precision(P):</h3>\n",
        "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">The fraction of true positives (TP, correct predictions) from the total amount of relevant results, i.e., the sum of TP and false positives (FP). For multi-class classification problems, P is averaged among the classes. The following is the formula for precision.</p>\n",
        "\n",
        "<h4> <center>$P=TP/(TP+FP)$</center></h4>\n",
        "\n",
        "<h3>Recall(R): </h3>\n",
        "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">The fraction of TP from the total amount of TP and false negatives (FN). For multi-class classification problems, R gets averaged among all the classes. The following is the formula for recall.</p>\n",
        "<h4><center>$R=TP/(TP+FN)$</center></h4>\n",
        "\n",
        "<h3>F1 score(F1): </h3>\n",
        "\n",
        "<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">The harmonic mean of precision and recall. For multi-class classification problems, F1 gets averaged among all the classes. The following is the formula for F1 score.</p>\n",
        "<h4><center>$F1=2 * (TP * FP)/(TP+FP)$</center></h4>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_BWrofxS2vO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_images, verbose=0)\n",
        "\n",
        "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
        "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
      ],
      "metadata": {
        "id": "CS-g90hJ340B",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:57.136163Z",
          "iopub.status.idle": "2023-12-25T15:33:57.137592Z",
          "shell.execute_reply.started": "2023-12-25T15:33:57.137242Z",
          "shell.execute_reply": "2023-12-25T15:33:57.137278Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìâVisualizing loss curves"
      ],
      "metadata": {
        "id": "t5oGHvsG368q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "01SS6RVx38o7",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:57.139931Z",
          "iopub.status.idle": "2023-12-25T15:33:57.140576Z",
          "shell.execute_reply.started": "2023-12-25T15:33:57.140247Z",
          "shell.execute_reply": "2023-12-25T15:33:57.140281Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîÆMaking predictions on the Test Data"
      ],
      "metadata": {
        "id": "0BL7xgPz4Fv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the label of the test_images\n",
        "pred = model.predict(test_images)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "\n",
        "# Map the label\n",
        "labels = (train_images.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "pred = [labels[k] for k in pred]\n",
        "\n",
        "# Display the result\n",
        "print(f'The first 5 predictions: {pred[:5]}')"
      ],
      "metadata": {
        "id": "KxAegJBB4HlW",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:57.143164Z",
          "iopub.status.idle": "2023-12-25T15:33:57.144088Z",
          "shell.execute_reply.started": "2023-12-25T15:33:57.143806Z",
          "shell.execute_reply": "2023-12-25T15:33:57.143857Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display 25 random pictures from the dataset with their labels\n",
        "random_index = np.random.randint(0, len(test_df) - 1, 15)\n",
        "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(test_df.Filepath.iloc[random_index[i]]))\n",
        "    if test_df.Label.iloc[random_index[i]] == pred[random_index[i]]:\n",
        "        color = \"green\"\n",
        "    else:\n",
        "        color = \"red\"\n",
        "    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\", color=color)\n",
        "plt.show()\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "pWO4e4wb4Iln",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:57.146013Z",
          "iopub.status.idle": "2023-12-25T15:33:57.146537Z",
          "shell.execute_reply.started": "2023-12-25T15:33:57.146309Z",
          "shell.execute_reply": "2023-12-25T15:33:57.146334Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìäPlotting the Classification Reports and Confusion Matrix"
      ],
      "metadata": {
        "id": "jLYd5vYJ4KTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = list(test_df.Label)\n",
        "print(classification_report(y_test[:-11], pred))"
      ],
      "metadata": {
        "id": "6ySAZoU74MlB",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:57.148424Z",
          "iopub.status.idle": "2023-12-25T15:33:57.149163Z",
          "shell.execute_reply.started": "2023-12-25T15:33:57.148892Z",
          "shell.execute_reply": "2023-12-25T15:33:57.148924Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test[:-11], pred, output_dict=True)\n",
        "df = pd.DataFrame(report).transpose()\n",
        "df"
      ],
      "metadata": {
        "id": "bYWvkbXI4Ns2",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:57.151211Z",
          "iopub.status.idle": "2023-12-25T15:33:57.151703Z",
          "shell.execute_reply.started": "2023-12-25T15:33:57.151466Z",
          "shell.execute_reply": "2023-12-25T15:33:57.151490Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(15, 7), text_size=10, norm=False, savefig=False):\n",
        "    \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "    If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "\n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "    \"\"\"\n",
        "  # Create the confustion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "    n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "    # Plot the figure and make it pretty\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Are there a list of classes?\n",
        "    if classes:\n",
        "        labels = classes\n",
        "    else:\n",
        "        labels = np.arange(cm.shape[0])\n",
        "\n",
        "    # Label the axes\n",
        "    ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes),\n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "\n",
        "    # Make x-axis labels appear on bottom\n",
        "    ax.xaxis.set_label_position(\"bottom\")\n",
        "    ax.xaxis.tick_bottom()\n",
        "    ### Added: Rotate xticks for readability & increase font size (required due to such a large confusion matrix)\n",
        "    plt.xticks(rotation=90, fontsize=text_size)\n",
        "    plt.yticks(fontsize=text_size)\n",
        "\n",
        "    # Set the threshold for different colors\n",
        "    threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "    # Plot the text on each cell\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if norm:\n",
        "            plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "                horizontalalignment=\"center\",\n",
        "                color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "                size=text_size)\n",
        "        else:\n",
        "            plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "    if savefig:\n",
        "        fig.savefig(\"confusion_matrix.png\")\n"
      ],
      "metadata": {
        "id": "QS8khAfS4Oy3",
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:57.154184Z",
          "iopub.status.idle": "2023-12-25T15:33:57.155062Z",
          "shell.execute_reply.started": "2023-12-25T15:33:57.154790Z",
          "shell.execute_reply": "2023-12-25T15:33:57.154816Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_confusion_matrix(y_test[:-11], pred, list(labels.values()))"
      ],
      "metadata": {
        "id": "vMsUQM6n4Pyx",
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:57.156384Z",
          "iopub.status.idle": "2023-12-25T15:33:57.157568Z",
          "shell.execute_reply.started": "2023-12-25T15:33:57.157325Z",
          "shell.execute_reply": "2023-12-25T15:33:57.157352Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚òÄÔ∏èGrad-Cam Visualization\n",
        "\n",
        "**Source code inspiration can be found [here](https://www.kaggle.com/code/databeru/visual-explanations-from-deep-networks-grad-cam)**"
      ],
      "metadata": {
        "id": "5axmmOMVnlri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img_array(img_path, size):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size \"size\"\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
        "    # Load the original image\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "    # Save the superimposed image\n",
        "    superimposed_img.save(cam_path)\n",
        "\n",
        "    # Display Grad CAM\n",
        "#     display(Image(cam_path))\n",
        "\n",
        "    return cam_path\n",
        "\n",
        "\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions\n",
        "\n",
        "last_conv_layer_name = \"Conv_1\"\n",
        "img_size = (224,224, 3)\n",
        "\n",
        "# Remove last layer's softmax\n",
        "model.layers[-1].activation = None"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:57.159553Z",
          "iopub.status.idle": "2023-12-25T15:33:57.160146Z",
          "shell.execute_reply.started": "2023-12-25T15:33:57.159909Z",
          "shell.execute_reply": "2023-12-25T15:33:57.159934Z"
        },
        "trusted": true,
        "id": "JQinuOkAnlri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the part of the pictures used by the neural network to classify the pictures\n",
        "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 10),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img_path = test_df.Filepath.iloc[random_index[i]]\n",
        "    img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
        "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "    cam_path = save_and_display_gradcam(img_path, heatmap)\n",
        "    ax.imshow(plt.imread(cam_path))\n",
        "    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-25T15:33:57.161896Z",
          "iopub.status.idle": "2023-12-25T15:33:57.162379Z",
          "shell.execute_reply.started": "2023-12-25T15:33:57.162151Z",
          "shell.execute_reply": "2023-12-25T15:33:57.162175Z"
        },
        "trusted": true,
        "id": "DUA49lgFnlri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "<div style=\"color:white;\n",
        "           display:fill;\n",
        "           border-radius:5px;\n",
        "           background-color:#5642C5;\n",
        "           font-size:110%;\n",
        "           font-family:Verdana;\n",
        "           letter-spacing:0.5px\">\n",
        "        <p style=\"padding: 10px;\n",
        "              color:white;\">\n",
        "            Thanks for viewing my work. If you like it, consider sharing it to others or give feedback to improve the notebook. Have a beautiful day my friend.\n",
        "        </p>\n",
        "    </div>\n",
        "\n",
        "<center><img src='https://media4.giphy.com/media/M9gbBd9nbDrOTu1Mqx/giphy.gif?cid=790b7611704aa2ca4e403287801480a6c753abf45f3e6242&rid=giphy.gif&ct=s'\n",
        "     height=30px width=160px /></center>"
      ],
      "metadata": {
        "id": "k7og7cf-nlri"
      }
    }
  ]
}